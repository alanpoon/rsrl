[package]
name = "rsrl"
description = "A fast, extensible reinforcement learning framework in Rust"

version = "0.7.0"
authors = ["Tom Spooner <t.spooner@liverpool.ac.uk>"]

license = "MIT"
readme = "README.md"

keywords = ["machine", "reinforcement", "learning", "rl", "ai"]

repository = "https://github.com/tspooner/rsrl"
documentation = "https://docs.rs/rsrl"

edition = "2018"

[badges]
travis-ci = { repository = "tspooner/rsrl", branch = "master" }
coveralls = { repository = "tspooner/rsrl", branch = "master", service = "github" }

[features]
default = []

serialize = ["lfa/serialize", "spaces/serialize", "ndarray/serde-1"]

[dependencies]
lfa = "0.13"
rstat = {version="0.4",features =[]}
spaces = "5.0"

rsrl_domains = { path = "../rsrl_domains", version = "0.1" }

rand = "0.7"
rand_distr = "0.2"

ndarray = { path = "../../ndarray" }
special-fun = "0.2"
nalgebra = "0.21.0"
serde = { version = "1.0", features = ["derive"] }

slog = "2.5"
slog-term = "2.4"
slog-async = "2.3"

[dev-dependencies]
quickcheck = "0.9"

serde_test = "1.0"